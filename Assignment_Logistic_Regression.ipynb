{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Assignment Questions**"
      ],
      "metadata": {
        "id": "vOc86PqYgwVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Theoretical**"
      ],
      "metadata": {
        "id": "OujIUV1XfkVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q1. What is Logistic Regression, and how does it differ from Linear Regression?**"
      ],
      "metadata": {
        "id": "NXLwmiKqfkVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "-  Linear Regression predicts continuous values (e.g., price, temperature).  \n",
        "-  Logistic Regression predicts probabilities for classification (e.g., spam or not).  \n",
        "-  Linear uses a straight-line equation; Logistic uses a sigmoid function.  \n",
        "-  Linear output ranges from \\(-\\infty\\) to \\(+\\infty\\); Logistic ranges from 0 to 1.  \n",
        "- Linear minimizes Mean Squared Error; Logistic uses Cross-Entropy Loss.  \n",
        "-  Logistic sets a threshold (like 0.5) to classify outputs as 0 or 1.  \n",
        "\n"
      ],
      "metadata": {
        "id": "JZ62IiHOfkVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q2. What is the mathematical equation of Logistic Regression?**"
      ],
      "metadata": {
        "id": "ZFY2bmVGfkVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mathematical equation of **Logistic Regression** models the probability that a given input belongs to a particular class (typically class 1). Here's\n",
        "\n",
        "---\n",
        "\n",
        "### Logistic Regression Equation\n",
        "\n",
        "\\[\n",
        "P(y = 1 \\mid \\mathbf{x}) = \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "\\]\n",
        "Where:\n",
        "- \\( \\sigma(z) \\) is the **sigmoid function**\n",
        "- \\( z = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_nx_n \\)\n",
        "- \\( \\mathbf{x} = (x_1, x_2, \\dots, x_n) \\) are the input features\n",
        "- \\( \\beta_0 \\) is the intercept (bias), and \\( \\beta_i \\) are the model coefficients\n",
        "\n",
        "---\n",
        "\n",
        "### Interpretation\n",
        "\n",
        "- The output \\( P(y = 1 \\mid \\mathbf{x}) \\) is the **probability** that the input belongs to class 1.\n",
        "- To classify, we typically use a **threshold** (e.g., if \\( P > 0.5 \\), predict class 1; else class 0).\n"
      ],
      "metadata": {
        "id": "NPZwxwcnfkVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q3. Why do we use the Sigmoid function in Logistic Regression?**"
      ],
      "metadata": {
        "id": "Y03nios9fkVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the sigmoid function in logistic regression because:\n",
        "\n",
        "- It converts any real number into a value between 0 and 1, representing probability  \n",
        "- It allows us to classify outputs using a threshold (typically 0.5)  \n",
        "- It transforms a linear equation into a non-linear probability curve  \n",
        "- It is smooth and differentiable, making it suitable for optimization using gradient descent  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vnqhoWp9PB6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q4. What is the cost function of Logistic Regression?**"
      ],
      "metadata": {
        "id": "NlU72YrhfkVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-- Cost Function of Logistic Regression:\n",
        "\n",
        "In **Machine Learning**, the **cost function** for **Logistic Regression** is based on **binary cross-entropy (log loss)**:\n",
        "\n",
        "$$\n",
        "J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\Big[ y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)})) \\Big]\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "--For a Single Training Example:\n",
        "\n",
        "$$\n",
        "\\text{Cost}(p, y) = - \\left[ y \\cdot \\log(p) + (1 - y) \\cdot \\log(1 - p) \\right]\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "* $y$ = actual label (0 or 1)\n",
        "* $p = h_\\theta(x)$ = predicted probability using the **sigmoid function**:\n",
        "\n",
        "  $$\n",
        "  h_\\theta(x) = \\frac{1}{1 + e^{-\\theta^T x}}\n",
        "  $$\n",
        "\n",
        "---\n",
        "\n",
        "-- Goal:\n",
        "\n",
        "Minimize this cost function by adjusting parameters $\\theta$ using algorithms like **gradient descent**, so predictions get closer to actual labels.\n"
      ],
      "metadata": {
        "id": "r6ZV_jvISLaP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q5. What is Regularization in Logistic Regression? Why is it needed?**"
      ],
      "metadata": {
        "id": "rlO6pQZofkVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Regularization** in Logistic Regression is a technique to **prevent overfitting** by adding a **penalty** to the cost function when model parameters become too large.\n",
        "\n",
        "---\n",
        "\n",
        "-- Modified Cost Function (with L2 Regularization):\n",
        "\n",
        "$$\n",
        "J(\\theta) = \\text{Original Cost} + \\frac{\\lambda}{2m} \\sum \\theta_j^2\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "-- Why It Is Needed:\n",
        "\n",
        "* Prevents the model from fitting noise in the training data\n",
        "* Controls complexity by discouraging large weights\n",
        "* Improves performance on unseen (test) data\n",
        "\n",
        "---\n",
        "\n",
        "**Result:** A more general, stable, and accurate model.\n"
      ],
      "metadata": {
        "id": "M1Pr2_SISs4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q6. Explain the difference between Lasso, Ridge, and Elastic Net regression?**"
      ],
      "metadata": {
        "id": "dYUTG3EwfkVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**-Difference Between Lasso, Ridge, and Elastic Net Regression:-**\n",
        "\n",
        "These are regularization techniques used to reduce overfitting by adding penalty terms to the loss function in regression models.\n",
        "\n",
        "---\n",
        "\n",
        "1. **Ridge Regression (L2 Regularization)**\n",
        "\n",
        "* **Adds squared coefficients** to the loss function:\n",
        "\n",
        "  $$\n",
        "  \\frac{\\lambda}{2m} \\sum \\theta_j^2\n",
        "  $$\n",
        "* **Effect:** Shrinks all coefficients but **does not reduce any to zero**\n",
        "* **Use case:** Useful when most features are relevant and multicollinearity exists\n",
        "\n",
        "---\n",
        "\n",
        "2. **Lasso Regression (L1 Regularization)**\n",
        "\n",
        "* **Adds absolute values of coefficients** to the loss function:\n",
        "\n",
        "  $$\n",
        "  \\frac{\\lambda}{m} \\sum |\\theta_j|\n",
        "  $$\n",
        "* **Effect:** Can shrink some coefficients **exactly to zero**\n",
        "* **Use case:** Effective for **feature selection** in models with many irrelevant features\n",
        "\n",
        "---\n",
        "\n",
        "3. **Elastic Net Regression**\n",
        "\n",
        "* **Combines both L1 and L2 penalties**:\n",
        "\n",
        "  $$\n",
        "  \\lambda \\left[ \\alpha \\sum |\\theta_j| + (1 - \\alpha) \\sum \\theta_j^2 \\right]\n",
        "  $$\n",
        "* **Effect:** Mix of shrinking and zeroing out coefficients\n",
        "* **Use case:** When you want the benefits of both Ridge (stability) and Lasso (sparsity)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "lKnuIcnCS_TR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q7. When should we use Elastic Net instead of Lasso or Ridge?**"
      ],
      "metadata": {
        "id": "Y7xt-J4zfkVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When to Use **Elastic Net** Instead of **Lasso** or **Ridge**:\n",
        "\n",
        "Use **Elastic Net** when:\n",
        "\n",
        "---\n",
        "\n",
        "1. **There are many features**, and **some are highly correlated**\n",
        "\n",
        "   * Lasso tends to pick just one feature from a group of correlated ones and ignore the rest\n",
        "   * Elastic Net can keep multiple correlated features by blending L1 and L2\n",
        "\n",
        "---\n",
        "\n",
        "2. **You expect only some features to be important**, but not as few as Lasso would select\n",
        "\n",
        "   * Lasso may remove too many features\n",
        "   * Elastic Net allows some sparsity, but not too aggressive\n",
        "\n",
        "---\n",
        "\n",
        "3. **Lasso is unstable on your dataset**\n",
        "\n",
        "   * If Lasso's feature selection changes a lot with small data changes, Elastic Net offers more stability due to the L2 component\n",
        "\n",
        "---\n",
        "\n",
        "4. **You want both regularization and feature selection**\n",
        "\n",
        "   * Ridge: good for regularization\n",
        "   * Lasso: good for feature selection\n",
        "   * Elastic Net: combines both, gives you control using the $\\alpha$ parameter (balance between L1 and L2)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "R-OKfe3wTQXo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q8. What is the impact of the regularization parameter (λ) in Logistic Regression?**"
      ],
      "metadata": {
        "id": "q9bvdzDhfkVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--Impact of the Regularization Parameter $\\lambda$ in Logistic Regression:\n",
        "\n",
        "The parameter $\\lambda$ controls the **strength of regularization** in the cost function.\n",
        "\n",
        "---\n",
        "\n",
        "1. **When $\\lambda$ is Small (≈ 0):**\n",
        "\n",
        "* Very **little regularization**\n",
        "* Model tries to **fit training data as closely as possible**\n",
        "* **High risk of overfitting**\n",
        "\n",
        "---\n",
        "\n",
        "2. **When $\\lambda$ is Large:**\n",
        "\n",
        "* **Strong regularization** effect\n",
        "* Coefficients $\\theta$ are **heavily penalized** (shrunk)\n",
        "* Model becomes **simpler**\n",
        "* May cause **underfitting**, missing important patterns\n",
        "\n",
        "---\n",
        "\n",
        "3. **Optimal $\\lambda$:**\n",
        "\n",
        "* **Balances bias and variance**\n",
        "* Found using techniques like **cross-validation**\n",
        "\n",
        "---\n",
        "\n",
        "Summary:\n",
        "\n",
        "* **Small $\\lambda$:** low bias, high variance (risk of overfitting)\n",
        "* **Large $\\lambda$:** high bias, low variance (risk of underfitting)\n",
        "* **Ideal $\\lambda$:** gives the best generalization on unseen data\n",
        "\n"
      ],
      "metadata": {
        "id": "MjQq9TxAY31A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q9. What are the key assumptions of Logistic Regression?**"
      ],
      "metadata": {
        "id": "70cqVEPjfkVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Assumptions of Logistic Regression :\n",
        "\n",
        "1. **Binary Output**: Dependent variable must be 0 or 1\n",
        "2. **Independent Observations**: No duplicate or related data points\n",
        "3. **Linearity of Log-Odds**: Logit (not probability) is linearly related to predictors\n",
        "4. **No Multicollinearity**: Predictors shouldn’t be highly correlated\n",
        "5. **Large Sample Size**: Works better with more data\n",
        "6. **No Extreme Outliers**: Outliers can distort results\n",
        "\n",
        "These ensure reliable and interpretable logistic regression results.\n"
      ],
      "metadata": {
        "id": "GBEEGI7xZIr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q10. What are some alternatives to Logistic Regression for classification tasks?**"
      ],
      "metadata": {
        "id": "jmomaZFcfkVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatives to Logistic Regression :\n",
        "\n",
        "1. **Decision Trees** – Easy to interpret, handles non-linear data\n",
        "2. **Random Forest** – Ensemble of trees, more accurate\n",
        "3. **SVM** – Good for high-dimensional and non-linear data\n",
        "4. **k-NN** – Simple, no training, slow on large data\n",
        "5. **Naive Bayes** – Fast, good for text, assumes independence\n",
        "6. **Gradient Boosting (XGBoost)** – High accuracy, needs tuning\n",
        "7. **Neural Networks** – Best for complex, large data sets\n",
        "\n"
      ],
      "metadata": {
        "id": "9x2WL8opZZTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q11. What are Classification Evaluation Metrics?**"
      ],
      "metadata": {
        "id": "FQrVB84DfkVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---Classification Evaluation Metrics :\n",
        "\n",
        "1. **Accuracy**\n",
        "\n",
        "   * Proportion of correct predictions:\n",
        "\n",
        "     $$\n",
        "     \\frac{TP + TN}{TP + TN + FP + FN}\n",
        "     $$\n",
        "\n",
        "2. **Precision**\n",
        "\n",
        "   * Correct positive predictions out of total predicted positives:\n",
        "\n",
        "     $$\n",
        "     \\frac{TP}{TP + FP}\n",
        "     $$\n",
        "\n",
        "3. **Recall (Sensitivity / TPR)**\n",
        "\n",
        "   * Correct positive predictions out of actual positives:\n",
        "\n",
        "     $$\n",
        "     \\frac{TP}{TP + FN}\n",
        "     $$\n",
        "\n",
        "4. **F1-Score**\n",
        "\n",
        "   * Harmonic mean of precision and recall:\n",
        "\n",
        "     $$\n",
        "     2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "     $$\n",
        "\n",
        "5. **ROC-AUC Score**\n",
        "\n",
        "   * Measures model's ability to distinguish classes (area under ROC curve)\n",
        "\n",
        "6. **Confusion Matrix**\n",
        "\n",
        "   * Table showing TP, FP, TN, FN counts\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "aJKyNr4ScBJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q12. How does class imbalance affect Logistic Regression?**"
      ],
      "metadata": {
        "id": "qQWvj7kbfkVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----**Impact of Class Imbalance on Logistic Regression :**-----\n",
        "\n",
        "1. **Biased Predictions**\n",
        "\n",
        "   * The model may predict the **majority class** most of the time, ignoring the minority.\n",
        "\n",
        "2. **Misleading Accuracy**\n",
        "\n",
        "   * High accuracy may be meaningless if the model just predicts the majority class.\n",
        "\n",
        "3. **Poor Recall for Minority Class**\n",
        "\n",
        "   * The model may **miss most positive cases**, especially in rare-event detection.\n",
        "\n",
        "4. **Poor Model Generalization**\n",
        "\n",
        "   * Learns patterns mostly from the dominant class, leading to **weak minority detection**.\n",
        "\n",
        "---\n",
        "\n",
        "--Solutions:\n",
        "\n",
        "* Use **resampling techniques** (oversampling, undersampling)\n",
        "* Apply **class weights** to penalize mistakes on the minority class\n",
        "* Evaluate using **precision, recall, F1-score**, not just accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "V-H32ukJcTgF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q13. What is Hyperparameter Tuning in Logistic Regression?**"
      ],
      "metadata": {
        "id": "1mjuqwsYfkVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-- Hyperparameter Tuning in Logistic Regression :\n",
        "\n",
        "**Hyperparameter tuning** is the process of selecting the best settings that control how the Logistic Regression model learns.\n",
        "\n",
        "---\n",
        "\n",
        "-- Common Hyperparameters:\n",
        "\n",
        "1. **Regularization strength ($C$)**\n",
        "\n",
        "   * Inverse of regularization parameter $\\lambda$:\n",
        "     Smaller $C$ → stronger regularization\n",
        "\n",
        "2. **Penalty type**\n",
        "\n",
        "   * `'l1'`, `'l2'`, or `'elasticnet'`\n",
        "   * Controls type of regularization\n",
        "\n",
        "3. **Solver**\n",
        "\n",
        "   * Optimization algorithm (e.g., `'liblinear'`, `'saga'`, `'newton-cg'`)\n",
        "   * Some solvers only support specific penalties\n",
        "\n"
      ],
      "metadata": {
        "id": "gIYaijbccku6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q14. What are different solvers in Logistic Regression? Which one should be used?**"
      ],
      "metadata": {
        "id": "F5azWRKDfkVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---- Solvers in Logistic Regression :\n",
        "\n",
        "Solvers are optimization algorithms used to fit the model by minimizing the cost function.\n",
        "\n",
        "---\n",
        "\n",
        "--- Common Solvers:\n",
        "\n",
        "1. **liblinear**\n",
        "\n",
        "   * Good for small datasets\n",
        "   * Supports **L1 and L2 penalties**\n",
        "   * Works only for **binary classification**\n",
        "\n",
        "2. **lbfgs**\n",
        "\n",
        "   * Fast and accurate for **L2 penalty**\n",
        "   * Suitable for **multiclass** problems\n",
        "   * Preferred for **medium to large datasets**\n",
        "\n",
        "3. **newton-cg**\n",
        "\n",
        "   * Supports **L2 penalty**\n",
        "   * Better for multiclass, **sparse features**, and large datasets\n",
        "\n",
        "4. **sag (Stochastic Average Gradient)**\n",
        "\n",
        "   * Efficient for **large datasets**\n",
        "   * Works with **L2 penalty only**\n",
        "\n",
        "5. **saga**\n",
        "\n",
        "   * Handles **L1, L2, and elastic net**\n",
        "   * Works for **large-scale and sparse data**\n",
        "   * Suitable for both **binary and multiclass**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GPOuhdopcyh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q15. How is Logistic Regression extended for multiclass classification?**"
      ],
      "metadata": {
        "id": "dcZxnxT5fkVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---Logistic Regression for Multiclass Classification :\n",
        "\n",
        "Logistic Regression is naturally binary, but it can be extended to **multiclass problems** using:\n",
        "\n",
        "---\n",
        "\n",
        "1. **One-vs-Rest (OvR) / One-vs-All**\n",
        "\n",
        "* Trains one classifier per class:\n",
        "  Each model distinguishes one class vs. all others\n",
        "* Final prediction: class with the highest probability\n",
        "* **Default method in scikit-learn**\n",
        "\n",
        "---\n",
        "\n",
        "2. **Multinomial Logistic Regression (Softmax Regression)**\n",
        "\n",
        "* Generalizes logistic regression using the **softmax function**\n",
        "* Trains a **single model** that handles all classes together\n",
        "* Preferred when classes are **mutually exclusive**\n",
        "* Use `solver='lbfgs'` or `solver='saga'` with `multi_class='multinomial'`\n",
        "\n",
        "---\n",
        "\n",
        " --- When to Use:\n",
        "\n",
        "* **OvR**: Simpler, works well when classes are imbalanced\n",
        "* **Multinomial**: Better for performance and probability calibration in balanced, multiclass tasks\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2ocVi28kdJjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q16. What are the advantages and disadvantages of Logistic Regression?**"
      ],
      "metadata": {
        "id": "83NOVYWUfkVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---Advantages and Disadvantages of Logistic Regression :\n",
        "\n",
        "---\n",
        "\n",
        "--**Advantages:**\n",
        "\n",
        "1. **Simple and Fast**\n",
        "\n",
        "   * Easy to implement, train, and interpret\n",
        "\n",
        "2. **Probabilistic Output**\n",
        "\n",
        "   * Gives class probabilities (not just labels)\n",
        "\n",
        "3. **Efficient for Linearly Separable Data**\n",
        "\n",
        "   * Performs well when classes are linearly separable\n",
        "\n",
        "4. **Works Well with Few Features**\n",
        "\n",
        "   * Effective even with small datasets\n",
        "\n",
        "5. **Regularization Support**\n",
        "\n",
        "   * Handles overfitting with L1/L2 regularization\n",
        "\n",
        "---\n",
        "\n",
        "---**Disadvantages:**\n",
        "\n",
        "1. **Assumes Linear Relationship (in log-odds)**\n",
        "\n",
        "   * Fails if the relationship is highly non-linear\n",
        "\n",
        "2. **Not Suitable for Complex Patterns**\n",
        "\n",
        "   * Performs poorly with high-dimensional, complex data\n",
        "\n",
        "3. **Sensitive to Outliers**\n",
        "\n",
        "   * Outliers can skew predictions\n",
        "\n",
        "4. **Struggles with Multicollinearity**\n",
        "\n",
        "   * Highly correlated inputs affect model stability\n",
        "\n",
        "5. **Limited to Binary/Multiclass Classification**\n",
        "\n",
        "   * Not for regression or ordinal classification\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mKBCBgVlddZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q17. What are some use cases of Logistic Regression?**"
      ],
      "metadata": {
        "id": "PH1E_Rz0fkVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- Use Cases of Logistic Regression :\n",
        "\n",
        "1. **Email Spam Detection**\n",
        "\n",
        "   * Classify emails as spam or not spam (0 or 1)\n",
        "\n",
        "2. **Credit Scoring**\n",
        "\n",
        "   * Predict if a loan applicant will default or not\n",
        "\n",
        "3. **Medical Diagnosis**\n",
        "\n",
        "   * Determine if a patient has a disease (e.g., cancer detection)\n",
        "\n",
        "4. **Customer Churn Prediction**\n",
        "\n",
        "   * Predict whether a customer will leave a service\n",
        "\n",
        "5. **Marketing Campaign Response**\n",
        "\n",
        "   * Estimate the likelihood of a customer responding to an offer\n",
        "\n",
        "6. **Fraud Detection**\n",
        "\n",
        "   * Classify transactions as fraudulent or genuine\n",
        "\n",
        "7. **Image Classification (Simple Binary Cases)**\n",
        "\n",
        "   * e.g., distinguishing cats vs. dogs with simple features\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vE_CqegXeQLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q18. What is the difference between Softmax Regression and Logistic Regression?**"
      ],
      "metadata": {
        "id": "Qp9-rV-yfkVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----Difference Between Logistic Regression and Softmax Regression (Short):\n",
        "\n",
        "---\n",
        "\n",
        "1. **Logistic Regression**\n",
        "\n",
        "* **Used for**: **Binary classification** (2 classes)\n",
        "* **Output**: Probability of one class (the other is 1 - p)\n",
        "* **Activation**: Uses **sigmoid function**\n",
        "\n",
        "  $$\n",
        "  \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "  $$\n",
        "\n",
        "---\n",
        "\n",
        "2. **Softmax Regression (Multinomial Logistic Regression)**\n",
        "\n",
        "* **Used for**: **Multiclass classification** (3 or more classes)\n",
        "* **Output**: Probabilities for **all classes**, sum to 1\n",
        "* **Activation**: Uses **softmax function**\n",
        "\n",
        "  $$\n",
        "  P(y = k) = \\frac{e^{z_k}}{\\sum_{j} e^{z_j}}\n",
        "  $$\n",
        "\n",
        "---\n",
        "\n",
        "----Key Differences:\n",
        "\n",
        "| Feature             | Logistic Regression | Softmax Regression            |\n",
        "| ------------------- | ------------------- | ----------------------------- |\n",
        "| Classification Type | Binary (2 classes)  | Multiclass (3+ classes)       |\n",
        "| Output              | One probability     | Probabilities for all classes |\n",
        "| Function Used       | Sigmoid             | Softmax                       |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jU6Qq1CPelJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?**"
      ],
      "metadata": {
        "id": "ouJGUX6KfkVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- Choosing Between One-vs-Rest (OvR) and Softmax (Multinomial) for Multiclass Classification:\n",
        "\n",
        "---\n",
        "--- Use **Softmax (Multinomial Logistic Regression)** when:\n",
        "\n",
        "* Classes are **mutually exclusive**\n",
        "* You want **probabilities for all classes** at once\n",
        "* You need **better calibration and consistency**\n",
        "* Dataset is **balanced** and large\n",
        "* Preferred for **performance-focused models**\n",
        "\n",
        "---\n",
        "\n",
        "----Use **One-vs-Rest (OvR)** when:\n",
        "\n",
        "* You want a **simple, interpretable** approach\n",
        "* Your classes are **imbalanced**\n",
        "* You want to use **binary classifiers independently**\n",
        "* Easier to debug or modify per class\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "d9hAvDxXezMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Q20. How do we interpret coefficients in Logistic Regression?**"
      ],
      "metadata": {
        "id": "evCtl9YnfkVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---- Interpreting Coefficients in Logistic Regression :\n",
        "\n",
        "In Logistic Regression, each coefficient $\\theta_j$ represents the **effect of one unit change in feature $x_j$** on the **log-odds** of the outcome.\n",
        "\n",
        "---\n",
        "\n",
        "1. **Log-Odds Interpretation:**\n",
        "\n",
        "$$\n",
        "\\log\\left(\\frac{p}{1 - p}\\right) = \\theta_0 + \\theta_1 x_1 + \\dots + \\theta_j x_j\n",
        "$$\n",
        "\n",
        "* A one-unit increase in $x_j$ changes the **log-odds** by $\\theta_j$\n",
        "\n",
        "---\n",
        "\n",
        "2. **Odds Ratio Interpretation:**\n",
        "\n",
        "$$\n",
        "\\text{Odds Ratio} = e^{\\theta_j}\n",
        "$$\n",
        "\n",
        "* $e^{\\theta_j} > 1$: Increase in $x_j$ **increases** odds of the event\n",
        "* $e^{\\theta_j} < 1$: Increase in $x_j$ **decreases** odds\n",
        "* $e^{\\theta_j} = 1$: No effect\n",
        "\n",
        "---\n",
        "\n",
        "### Example:\n",
        "\n",
        "If $\\theta_j = 0.7$, then\n",
        "\n",
        "$$\n",
        "e^{0.7} \\approx 2.01\n",
        "$$\n",
        "\n",
        "→ A one-unit increase in $x_j$ **doubles** the odds of the positive outcome.\n",
        "\n"
      ],
      "metadata": {
        "id": "IRBzB4a2fBwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Practical**"
      ],
      "metadata": {
        "id": "izwRut8ZjB0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy?**"
      ],
      "metadata": {
        "id": "UvRLdKyPjDur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Step 2: Split the dataset (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 5: Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "JlS75vq9MZlS",
        "outputId": "d298c327-4499-40ec-f117-c79e567e3b2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy?**"
      ],
      "metadata": {
        "id": "TNvlfHphjxGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Step 2: Split into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train Logistic Regression with L1 regularization (Lasso)\n",
        "model = LogisticRegression(penalty='l1', solver='saga', max_iter=500, multi_class='multinomial')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 5: Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with L1 Regularization: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqDc7Sd3N2-m",
        "outputId": "f1a47d72-53a6-4bca-a5f8-69c4723f88fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L1 Regularization: 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients?**"
      ],
      "metadata": {
        "id": "_Y4z2ACuj5am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Step 2: Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train Logistic Regression with L2 regularization\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200, multi_class='multinomial')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 5: Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with L2 Regularization: {accuracy:.2f}\")\n",
        "\n",
        "# Step 6: Print model coefficients\n",
        "print(\"Model Coefficients:\")\n",
        "for idx, class_label in enumerate(iris.target_names):\n",
        "    print(f\"Class '{class_label}': {model.coef_[idx]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCrvepxiPYLn",
        "outputId": "146e5870-894f-476f-8e59-cd29578a1e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L2 Regularization: 1.00\n",
            "Model Coefficients:\n",
            "Class 'setosa': [-0.39345607  0.96251768 -2.37512436 -0.99874594]\n",
            "Class 'versicolor': [ 0.50843279 -0.25482714 -0.21301129 -0.77574766]\n",
            "Class 'virginica': [-0.11497673 -0.70769055  2.58813565  1.7744936 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')?**"
      ],
      "metadata": {
        "id": "lWZ2pCN_kCH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Step 2: Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Train Logistic Regression with Elastic Net\n",
        "model = LogisticRegression(\n",
        "    penalty='elasticnet',\n",
        "    solver='saga',\n",
        "    l1_ratio=0.5,           # Mix of L1 and L2 (Elastic Net)\n",
        "    max_iter=500,\n",
        "    multi_class='multinomial'\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Evaluate model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with Elastic Net Regularization: {accuracy:.2f}\")\n",
        "\n",
        "# Step 5: Print model coefficients\n",
        "print(\"Model Coefficients:\")\n",
        "for idx, class_label in enumerate(iris.target_names):\n",
        "    print(f\"Class '{class_label}': {model.coef_[idx]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_eGrDPfRfZ3",
        "outputId": "357cbe2e-8a5a-4175-ea15-3d2478d569e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with Elastic Net Regularization: 1.00\n",
            "Model Coefficients:\n",
            "Class 'setosa': [ 0.25513599  1.73427538 -2.43152985 -0.61863687]\n",
            "Class 'versicolor': [ 0.          0.          0.         -0.50817384]\n",
            "Class 'virginica': [-1.01094023 -1.20952171  2.64709377  2.10729418]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'?**"
      ],
      "metadata": {
        "id": "FYAwdMRjkIuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Step 2: Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Train Logistic Regression using One-vs-Rest (OvR)\n",
        "model = LogisticRegression(\n",
        "    multi_class='ovr',\n",
        "    solver='lbfgs',  # Supports OvR and is good for small to medium datasets\n",
        "    max_iter=200\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Evaluate model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with One-vs-Rest (OvR): {accuracy:.2f}\")\n",
        "\n",
        "# Step 5: Print model coefficients\n",
        "print(\"\\nModel Coefficients (One-vs-Rest):\")\n",
        "for idx, class_label in enumerate(iris.target_names):\n",
        "    print(f\"Class '{class_label}': {model.coef_[idx]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAcrJkKoTqk-",
        "outputId": "b48f5dea-2437-4873-ac83-9e7c8b6af5a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with One-vs-Rest (OvR): 0.97\n",
            "\n",
            "Model Coefficients (One-vs-Rest):\n",
            "Class 'setosa': [-0.42762216  0.88771927 -2.21471658 -0.91610036]\n",
            "Class 'versicolor': [-0.03387836 -2.0442989   0.54266011 -1.0179372 ]\n",
            "Class 'virginica': [-0.38904645 -0.62147609  2.7762982   2.09067085]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy?**"
      ],
      "metadata": {
        "id": "wMSkCQ03kXdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Step 2: Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Define the model\n",
        "model = LogisticRegression(solver='saga', max_iter=1000, multi_class='multinomial')\n",
        "\n",
        "# Step 4: Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2']  # Both L1 and L2 regularization\n",
        "}\n",
        "\n",
        "# Step 5: Apply GridSearchCV\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Best parameters and accuracy\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "print(f\"Test Set Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNM5prF4WPvB",
        "outputId": "e0d5e776-1603-4806-aacd-ec08f83a5fe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters:\n",
            "{'C': 10, 'penalty': 'l2'}\n",
            "Test Set Accuracy: 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy?**"
      ],
      "metadata": {
        "id": "6CHdspqKlv8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Step 2: Define Stratified K-Fold\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Step 3: Initialize model\n",
        "model = LogisticRegression(max_iter=200, solver='lbfgs', multi_class='multinomial')\n",
        "\n",
        "# Step 4: Cross-validation\n",
        "accuracies = []\n",
        "\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(acc)\n",
        "    print(f\"Fold Accuracy: {acc:.2f}\")\n",
        "\n",
        "# Step 5: Print average accuracy\n",
        "average_accuracy = np.mean(accuracies)\n",
        "print(f\"\\nAverage Accuracy across folds: {average_accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrIV8VTuYDcH",
        "outputId": "1e63f075-bc7e-4fdb-f9e9-1480e009db9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold Accuracy: 1.00\n",
            "Fold Accuracy: 0.97\n",
            "Fold Accuracy: 0.93\n",
            "Fold Accuracy: 1.00\n",
            "Fold Accuracy: 0.93\n",
            "\n",
            "Average Accuracy across folds: 0.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy?**"
      ],
      "metadata": {
        "id": "FKP4Q1Bul1sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data         # Features\n",
        "y = iris.target       # Target labels\n",
        "\n",
        "# Split into train and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Logistic Regression Accuracy on Iris dataset: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuzW2JSi-XE2",
        "outputId": "5a8d52de-3b55-4717-d685-8aa5dbf60d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy on Iris dataset: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy?**"
      ],
      "metadata": {
        "id": "9fVJm5aul7vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import loguniform\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split into training and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Define hyperparameter space\n",
        "param_dist = {\n",
        "    'C': loguniform(1e-4, 1e4),                  # Continuous range for regularization\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "    'solver': ['saga', 'liblinear', 'lbfgs', 'newton-cg', 'sag']\n",
        "}\n",
        "\n",
        "# Randomized search\n",
        "random_search = RandomizedSearchCV(\n",
        "    model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=30,  # Number of different combinations to try\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model and its performance\n",
        "best_model = random_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Output results\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(random_search.best_params_)\n",
        "print(f\"Test Set Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIbEZIsjAAO-",
        "outputId": "1d2546dc-9059-4914-b815-3cbad8d6a469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters:\n",
            "{'C': np.float64(3448.3714871953384), 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Test Set Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy?**"
      ],
      "metadata": {
        "id": "Xp2rnaLgmDQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Logistic Regression base model\n",
        "base_model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# One-vs-One (OvO) wrapper\n",
        "ovo_model = OneVsOneClassifier(base_model)\n",
        "\n",
        "# Train the OvO model\n",
        "ovo_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = ovo_model.predict(X_test)\n",
        "\n",
        "# Evaluate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"One-vs-One Logistic Regression Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvX0hzYyBd36",
        "outputId": "85fa22a9-00aa-46ed-d563-7931a731ce3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-vs-One Logistic Regression Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification?**"
      ],
      "metadata": {
        "id": "kZSbfYaZmIoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Generate a binary classification dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2,\n",
        "                           n_informative=5, random_state=42)\n",
        "\n",
        "# 2. Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Train a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 5. Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# 6. Plot confusion matrix using seaborn heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Pred 0', 'Pred 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.title('Confusion Matrix - Logistic Regression')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "NwuyOEKdB0Wo",
        "outputId": "bd450886-4c64-4ec7-cd61-2d7080e55b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[95 17]\n",
            " [16 72]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score?**"
      ],
      "metadata": {
        "id": "3RHOBidGmdxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Create a binary classification dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2,\n",
        "                           n_informative=5, random_state=42)\n",
        "\n",
        "# 2. Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Train a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 5. Evaluate performance\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# 6. Print results\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall:    {recall:.2f}\")\n",
        "print(f\"F1 Score:  {f1:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-GDgbylCn3D",
        "outputId": "ba84c5fc-43a4-4713-dc09-545cde787afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.81\n",
            "Recall:    0.82\n",
            "F1 Score:  0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance?**"
      ],
      "metadata": {
        "id": "V9iaq6qEmiGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# 1. Create an imbalanced binary classification dataset\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=10,\n",
        "    n_informative=5,\n",
        "    n_redundant=0,\n",
        "    n_clusters_per_class=1,\n",
        "    weights=[0.9, 0.1],  # 90% of class 0, 10% of class 1\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 2. Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 3. Train Logistic Regression WITHOUT class weights\n",
        "model_no_weights = LogisticRegression(max_iter=1000)\n",
        "model_no_weights.fit(X_train, y_train)\n",
        "y_pred_no_weights = model_no_weights.predict(X_test)\n",
        "\n",
        "# 4. Train Logistic Regression WITH balanced class weights\n",
        "model_weighted = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "model_weighted.fit(X_train, y_train)\n",
        "y_pred_weighted = model_weighted.predict(X_test)\n",
        "\n",
        "# 5. Evaluate both models\n",
        "print(\"=== Without Class Weights ===\")\n",
        "print(classification_report(y_test, y_pred_no_weights, digits=2))\n",
        "\n",
        "print(\"=== With Class Weights (Balanced) ===\")\n",
        "print(classification_report(y_test, y_pred_weighted, digits=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp1T_HjCFI9p",
        "outputId": "f0e0607c-3c6f-4824-9679-ac14f38eb59f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Without Class Weights ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       178\n",
            "           1       0.94      0.73      0.82        22\n",
            "\n",
            "    accuracy                           0.96       200\n",
            "   macro avg       0.95      0.86      0.90       200\n",
            "weighted avg       0.96      0.96      0.96       200\n",
            "\n",
            "=== With Class Weights (Balanced) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.89      0.94       178\n",
            "           1       0.50      0.86      0.63        22\n",
            "\n",
            "    accuracy                           0.89       200\n",
            "   macro avg       0.74      0.88      0.78       200\n",
            "weighted avg       0.93      0.89      0.90       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance?**"
      ],
      "metadata": {
        "id": "RDJOE4mCmnsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\timport pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 1. Load Titanic dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# 2. Basic preprocessing\n",
        "# Drop rows with missing target\n",
        "df = df.dropna(subset=['survived'])\n",
        "\n",
        "# Fill missing values\n",
        "df['age'].fillna(df['age'].median(), inplace=True)\n",
        "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Drop columns that won't be used\n",
        "df = df.drop(columns=['deck', 'embark_town', 'alive', 'class', 'who', 'adult_male'])\n",
        "\n",
        "# Encode categorical features\n",
        "label_cols = ['sex', 'embarked']\n",
        "df[label_cols] = df[label_cols].apply(LabelEncoder().fit_transform)\n",
        "\n",
        "# 3. Define features and target\n",
        "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
        "X = df[features]\n",
        "y = df['survived']\n",
        "\n",
        "# 4. Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 5. Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 6. Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, y_pred, digits=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVrwLt3MFa00",
        "outputId": "254e4197-2e41-45c1-f46b-62723e693345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85       110\n",
            "           1       0.79      0.67      0.72        69\n",
            "\n",
            "    accuracy                           0.80       179\n",
            "   macro avg       0.80      0.78      0.79       179\n",
            "weighted avg       0.80      0.80      0.80       179\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling?**"
      ],
      "metadata": {
        "id": "XYtyCBpimtr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# 1. Create a synthetic dataset\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=10,\n",
        "    n_informative=5,\n",
        "    n_redundant=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 2. Artificially vary feature scales\n",
        "scaling_factors = np.array([1, 10, 100, 1, 10, 100, 1, 10, 100, 1])\n",
        "X *= scaling_factors\n",
        "\n",
        "# 3. Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 4. Logistic Regression WITHOUT Scaling\n",
        "model_no_scaling = LogisticRegression(C=0.01, max_iter=1000)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "acc_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "# 5. Standardize features (Z-score scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 6. Logistic Regression WITH Scaling\n",
        "model_scaled = LogisticRegression(C=0.01, max_iter=1000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "acc_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# 7. Compare results\n",
        "print(\"=== Logistic Regression Accuracy Comparison ===\")\n",
        "print(f\"Without Scaling: {acc_no_scaling:.2f}\")\n",
        "print(f\"With Scaling:    {acc_scaled:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41vpcCcjFnKo",
        "outputId": "f5383add-a148-49e2-a13a-2054b8ec3b81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Logistic Regression Accuracy Comparison ===\n",
            "Without Scaling: 0.81\n",
            "With Scaling:    0.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score?**"
      ],
      "metadata": {
        "id": "WK_ZUZUlmz9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Create a synthetic binary classification dataset\n",
        "X, y = make_classification(\n",
        "    n_samples=1000, n_features=10, n_informative=5,\n",
        "    n_classes=2, weights=[0.7, 0.3], random_state=42\n",
        ")\n",
        "\n",
        "# 2. Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 3. Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Predict probabilities for ROC-AUC\n",
        "y_probs = model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
        "\n",
        "# 5. Calculate ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_probs)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")\n",
        "\n",
        "# 6. Plot ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # Random chance line\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - Logistic Regression')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9qspQm23F4T9",
        "outputId": "59ad1bb0-96df-46ef-92a0-b8adeaf8992d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.86\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q17. Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy?**"
      ],
      "metadata": {
        "id": "GT69Wtz6m4Dr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset (Iris for multiclass)\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Initialize Logistic Regression with C=0.5\n",
        "model = LogisticRegression(C=0.5, max_iter=1000)\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with C=0.5: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9Xk0PPqGIfD",
        "outputId": "dd99b41e-3669-428a-e5c7-ff6035ee8fbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with C=0.5: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q18. Write a Python program to train Logistic Regression and identify important features based on model coefficients?**"
      ],
      "metadata": {
        "id": "sglVwgQrnApH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load breast cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Get coefficients\n",
        "coefficients = model.coef_[0]\n",
        "\n",
        "# Create DataFrame of feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': coefficients,\n",
        "    'AbsCoefficient': np.abs(coefficients)\n",
        "})\n",
        "\n",
        "# Sort by absolute coefficient\n",
        "feature_importance = feature_importance.sort_values(by='AbsCoefficient', ascending=False)\n",
        "\n",
        "print(\"Feature importance based on Logistic Regression coefficients:\")\n",
        "print(feature_importance[['Feature', 'Coefficient']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoILhOJUGWr3",
        "outputId": "40371c6f-4dee-4988-ae4a-6a475704effd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature importance based on Logistic Regression coefficients:\n",
            "                    Feature  Coefficient\n",
            "0               mean radius     2.099812\n",
            "26          worst concavity    -1.571347\n",
            "11            texture error     1.122469\n",
            "25        worst compactness    -1.004435\n",
            "20             worst radius     0.966303\n",
            "28           worst symmetry    -0.840956\n",
            "27     worst concave points    -0.693514\n",
            "6            mean concavity    -0.691207\n",
            "7       mean concave points    -0.408107\n",
            "5          mean compactness    -0.379844\n",
            "21            worst texture    -0.377126\n",
            "12          perimeter error    -0.325757\n",
            "24         worst smoothness    -0.317660\n",
            "8             mean symmetry    -0.235070\n",
            "4           mean smoothness    -0.170243\n",
            "1              mean texture     0.132486\n",
            "2            mean perimeter    -0.103468\n",
            "29  worst fractal dimension    -0.093083\n",
            "10             radius error    -0.085405\n",
            "13               area error    -0.065194\n",
            "15        compactness error     0.059602\n",
            "22          worst perimeter    -0.058583\n",
            "17     concave points error    -0.042776\n",
            "18           symmetry error    -0.041480\n",
            "23               worst area    -0.023960\n",
            "14         smoothness error    -0.023711\n",
            "9    mean fractal dimension    -0.023564\n",
            "19  fractal dimension error     0.014251\n",
            "16          concavity error     0.004522\n",
            "3                 mean area    -0.002556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q19. Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa Score?**"
      ],
      "metadata": {
        "id": "_HknNx8OnGdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# 1. Generate synthetic binary classification data\n",
        "X, y = make_classification(\n",
        "    n_samples=1000, n_features=10, n_classes=2,\n",
        "    n_informative=5, random_state=42\n",
        ")\n",
        "\n",
        "# 2. Split dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 5. Calculate Cohen's Kappa Score\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "print(f\"Cohen's Kappa Score: {kappa:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rKwRLzdGidv",
        "outputId": "5029b048-8d3d-457f-9879-f81ecd215ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa Score: 0.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification?**"
      ],
      "metadata": {
        "id": "Mg3uL2BTnMpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "# 1. Generate synthetic binary classification data\n",
        "X, y = make_classification(\n",
        "    n_samples=1000, n_features=10, n_classes=2,\n",
        "    weights=[0.7, 0.3], random_state=42\n",
        ")\n",
        "\n",
        "# 2. Split dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 3. Train Logistic Regression\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Predict probabilities for the positive class\n",
        "y_scores = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 5. Calculate precision, recall and thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "# 6. Calculate average precision score\n",
        "avg_precision = average_precision_score(y_test, y_scores)\n",
        "\n",
        "# 7. Plot Precision-Recall curve\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(recall, precision, label=f'Average Precision = {avg_precision:.2f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "DcC78DPwG0dQ",
        "outputId": "b348bca2-2b39-40b6-af78-d65e6ac0af94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy?**"
      ],
      "metadata": {
        "id": "x-uf-hqdnUDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# 1. Generate synthetic binary classification dataset\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=10,\n",
        "    n_informative=5,\n",
        "    n_redundant=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 2. Artificially vary feature scales\n",
        "X *= np.array([1, 10, 100, 1, 10, 100, 1, 10, 100, 1])\n",
        "\n",
        "# 3. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 4. Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 5. Solver and penalty combinations to compare\n",
        "configs = [\n",
        "    ('liblinear', 'l1'),\n",
        "    ('liblinear', 'l2'),\n",
        "    ('saga', 'l1'),\n",
        "    ('saga', 'l2'),\n",
        "    ('lbfgs', 'l2')\n",
        "]\n",
        "\n",
        "# 6. Store results\n",
        "accuracy_results = {}\n",
        "\n",
        "for solver, penalty in configs:\n",
        "    try:\n",
        "        model = LogisticRegression(\n",
        "            solver=solver,\n",
        "            penalty=penalty,\n",
        "            C=0.1,  # stronger regularization\n",
        "            max_iter=1000\n",
        "        )\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracy_results[f\"{solver}-{penalty}\"] = accuracy\n",
        "    except ValueError as e:\n",
        "        accuracy_results[f\"{solver}-{penalty}\"] = f\"Error: {e}\"\n",
        "\n",
        "# 7. Display results\n",
        "print(\"Logistic Regression Accuracy for Different Solvers and Penalties:\")\n",
        "for config, acc in accuracy_results.items():\n",
        "    print(f\"{config}: {acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfjynccxHIgh",
        "outputId": "48cb23b2-f35f-40f7-8d00-bd3708081f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy for Different Solvers and Penalties:\n",
            "liblinear-l1: 0.825\n",
            "liblinear-l2: 0.83\n",
            "saga-l1: 0.825\n",
            "saga-l2: 0.84\n",
            "lbfgs-l2: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC)?**"
      ],
      "metadata": {
        "id": "QMYp1zsWnbSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# 1. Generate synthetic binary classification data\n",
        "X, y = make_classification(\n",
        "    n_samples=1000, n_features=10, n_informative=5, random_state=42\n",
        ")\n",
        "\n",
        "# 2. Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 5. Calculate Matthews Correlation Coefficient\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlgwazWbHStm",
        "outputId": "6c2d05e5-fccd-473d-fe78-8188799e9c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient (MCC): 0.666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling?**"
      ],
      "metadata": {
        "id": "-W13Z9nDnhAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# 1. Generate synthetic dataset\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=10,\n",
        "    n_informative=5,\n",
        "    n_redundant=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 2. Artificially scale features to simulate real-world imbalance\n",
        "scaling_factors = np.array([1, 10, 100, 1, 10, 100, 1, 10, 100, 1])\n",
        "X *= scaling_factors\n",
        "\n",
        "# 3. Split dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# --- Without scaling ---\n",
        "model_raw = LogisticRegression(max_iter=1000, C=0.1)\n",
        "model_raw.fit(X_train, y_train)\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "acc_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "# --- With standardization ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=1000, C=0.1)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "acc_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# 4. Print and compare results\n",
        "print(\"=== Logistic Regression Accuracy Comparison ===\")\n",
        "print(\"Accuracy without feature scaling: {:.3f}\".format(acc_raw))\n",
        "print(\"Accuracy with standardization:   {:.3f}\".format(acc_scaled))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2TmM-b3H3Uc",
        "outputId": "04a6893e-9d61-4694-ca43-a8d7d6e8d690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Logistic Regression Accuracy Comparison ===\n",
            "Accuracy without feature scaling: 0.845\n",
            "Accuracy with standardization:   0.840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation?**"
      ],
      "metadata": {
        "id": "FHrqolgqnldQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Generate synthetic dataset\n",
        "X, y = make_classification(\n",
        "    n_samples=1000, n_features=10, n_informative=5, random_state=42\n",
        ")\n",
        "\n",
        "# 2. Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Define Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# 4. Define grid of C values to search\n",
        "param_grid = {'C': [0.01, 0.1, 0.5, 1, 5, 10, 50]}\n",
        "\n",
        "# 5. Setup GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# 6. Run GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 7. Best hyperparameter C\n",
        "best_C = grid_search.best_params_['C']\n",
        "print(f\"Best C: {best_C}\")\n",
        "\n",
        "# 8. Evaluate on test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test set accuracy with best C: {acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA-Gftm9ID4U",
        "outputId": "559ff8b3-5139-4470-adbf-f41128f407c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best C: 0.01\n",
            "Test set accuracy with best C: 0.830\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions?**"
      ],
      "metadata": {
        "id": "6HwgxA70npvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib  # for saving and loading models\n",
        "\n",
        "# 1. Generate synthetic dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
        "\n",
        "# 2. Split dataset into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Save the trained model to a file\n",
        "model_filename = 'logistic_regression_model.joblib'\n",
        "joblib.dump(model, model_filename)\n",
        "print(f\"Model saved to {model_filename}\")\n",
        "\n",
        "# --- Later or elsewhere in your code ---\n",
        "\n",
        "# 5. Load the saved model\n",
        "loaded_model = joblib.load(model_filename)\n",
        "print(\"Model loaded from disk.\")\n",
        "\n",
        "# 6. Make predictions using loaded model\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "\n",
        "# 7. Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of loaded model: {accuracy:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8rXYeX7IX_g",
        "outputId": "ae567722-11c2-4ee3-a351-be126aac7aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to logistic_regression_model.joblib\n",
            "Model loaded from disk.\n",
            "Accuracy of loaded model: 0.830\n"
          ]
        }
      ]
    }
  ]
}